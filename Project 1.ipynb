{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import dlc_practical_prologue as prologue\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([7, 3])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate train and test data\n",
    "#target classes: a>b->0   a<=b->1\n",
    "\n",
    "[train_input,train_target0,train_classes,\n",
    " test_input,test_target0,test_classes]=prologue.generate_pair_sets(1000)\n",
    "\n",
    "#train_target = train_target.float()\n",
    "train_target=torch.zeros(train_target0.size(0),2)\n",
    "test_target=torch.zeros(test_target0.size(0),2)\n",
    "for i in range(train_target0.size(0)):\n",
    "    train_target[i,train_target0[i]]=1.0;\n",
    "for i in range(test_target0.size(0)):\n",
    "    test_target[i,test_target0[i]]=1.0;\n",
    "\n",
    "fig=plt.figure(figsize=(4, 4))\n",
    "plt.imshow(train_input[0,0,:,:], cmap=plt.cm.gray)  # use appropriate colormap here\n",
    "plt.show()\n",
    "train_classes[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv -> maxpool -> relu\n",
    "class ConvNet1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet1, self).__init__()\n",
    "        nb_hidden = 200\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(16, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(8* 64, nb_hidden)\n",
    "        self.fc2 = nn.Linear(nb_hidden, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1=torch.zeros(1000,1,14,14)   \n",
    "        x2=torch.zeros(1000,1,14,14) \n",
    "        \n",
    "        x1[:,0,:,:]=x[:,0,:,:]\n",
    "        x2[:,0,:,:]=x[:,1,:,:]\n",
    "        \n",
    "        x1 = F.relu(F.max_pool2d(self.conv1(x1), kernel_size=2))\n",
    "        x2 = F.relu(F.max_pool2d(self.conv1(x2), kernel_size=2))\n",
    "        \n",
    "        x1 = F.relu(F.max_pool2d(self.conv2(x1), kernel_size=2))\n",
    "        x2 = F.relu(F.max_pool2d(self.conv2(x2), kernel_size=2))\n",
    "        \n",
    "        x1=x1.view(-1, 4 * 64)\n",
    "        x2=x2.view(-1, 4 * 64)\n",
    "        \n",
    "        x=torch.cat((x1,x2),1)\n",
    " \n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Conv -> relu -> maxpool\n",
    "#class ConvNet2(nn.Module):\n",
    "#    def __init__(self):\n",
    "#        super(ConvNet2, self).__init__()\n",
    "#        nb_hidden = 200\n",
    "#        self.conv1 = nn.Conv2d(2, 64, kernel_size=3)\n",
    "#        self.conv2 = nn.Conv2d(64, 64, kernel_size=3)\n",
    "#        self.fc1 = nn.Linear(4 * 64, nb_hidden)\n",
    "#        self.fc2 = nn.Linear(nb_hidden, 1)\n",
    "#\n",
    "#    def forward(self, x):\n",
    "#        x = F.max_pool2d(F.relu(self.conv1(x)), kernel_size=2)\n",
    "#        x = F.max_pool2d(F.relu(self.conv2(x)), kernel_size=2)\n",
    "#        x = F.relu(self.fc1(x.view(-1, 4 * 64)))\n",
    "#        x = self.fc2(x)\n",
    "#        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, mini_batch_size):\n",
    "    criterion = nn.MSELoss()\n",
    "    eta = 1e-4\n",
    "    nb_epochs = 100\n",
    "    for e in range(nb_epochs):\n",
    "        sum_loss = 0\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            \n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            sum_loss = sum_loss + loss.item()\n",
    "            for p in model.parameters():\n",
    "                p.data.sub_(eta * p.grad.data)\n",
    "        print(e, sum_loss)\n",
    "        \n",
    "        \n",
    "def compute_nb_errors(model, input, target, mini_batch_size):\n",
    "    nb_errors = 0\n",
    "\n",
    "    for b in range(0, input.size(0), mini_batch_size):\n",
    "        output = model(input.narrow(0, b, mini_batch_size))\n",
    "        _, predicted_classes = output.data.max(1)\n",
    "        \n",
    "        for k in range(mini_batch_size):\n",
    "            \n",
    "            if target.data[b + k, predicted_classes[k]] <= 0:\n",
    "                nb_errors = nb_errors + 1\n",
    "\n",
    "    return nb_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 145.44577026367188\n",
      "1 16991.455078125\n",
      "2 2.479444980621338\n",
      "3 1.9487388134002686\n",
      "4 1.6125191450119019\n",
      "5 1.3820093870162964\n",
      "6 1.2145205736160278\n",
      "7 1.0860204696655273\n",
      "8 0.9838164448738098\n",
      "9 0.9009888172149658\n",
      "10 0.8327144384384155\n",
      "11 0.7753196954727173\n",
      "12 0.7261207699775696\n",
      "13 0.6836514472961426\n",
      "14 0.6466916799545288\n",
      "15 0.6144295334815979\n",
      "16 0.5859824419021606\n",
      "17 0.560710072517395\n",
      "18 0.5381730198860168\n",
      "19 0.5180498957633972\n",
      "20 0.5000185966491699\n",
      "21 0.483742356300354\n",
      "22 0.4690137207508087\n",
      "23 0.4556829631328583\n",
      "24 0.4435451924800873\n",
      "25 0.43244266510009766\n",
      "26 0.4223228394985199\n",
      "27 0.41310176253318787\n",
      "28 0.4046403467655182\n",
      "29 0.3968775272369385\n",
      "30 0.38974156975746155\n",
      "31 0.3831577003002167\n",
      "32 0.37708190083503723\n",
      "33 0.3714817464351654\n",
      "34 0.36631956696510315\n",
      "35 0.3615718185901642\n",
      "36 0.3571924865245819\n",
      "37 0.3531360924243927\n",
      "38 0.3493768274784088\n",
      "39 0.34588733315467834\n",
      "40 0.3426513671875\n",
      "41 0.33963605761528015\n",
      "42 0.3368183374404907\n",
      "43 0.3341812193393707\n",
      "44 0.33171984553337097\n",
      "45 0.32942163944244385\n",
      "46 0.32726579904556274\n",
      "47 0.32525357604026794\n",
      "48 0.32336944341659546\n",
      "49 0.32159698009490967\n",
      "50 0.3199325501918793\n",
      "51 0.3183680474758148\n",
      "52 0.3168957531452179\n",
      "53 0.31551384925842285\n",
      "54 0.31421148777008057\n",
      "55 0.31298160552978516\n",
      "56 0.3118155002593994\n",
      "57 0.31071707606315613\n",
      "58 0.3096807897090912\n",
      "59 0.30870893597602844\n",
      "60 0.30778875946998596\n",
      "61 0.3069177567958832\n",
      "62 0.30609452724456787\n",
      "63 0.3053129315376282\n",
      "64 0.3045705258846283\n",
      "65 0.3038647174835205\n",
      "66 0.3031935393810272\n",
      "67 0.30255648493766785\n",
      "68 0.30194610357284546\n",
      "69 0.3013594150543213\n",
      "70 0.30079689621925354\n",
      "71 0.30025848746299744\n",
      "72 0.29974231123924255\n",
      "73 0.29924488067626953\n",
      "74 0.2987683117389679\n",
      "75 0.29831093549728394\n",
      "76 0.29787158966064453\n",
      "77 0.29744789004325867\n",
      "78 0.2970386743545532\n",
      "79 0.296642929315567\n",
      "80 0.29625943303108215\n",
      "81 0.29588937759399414\n",
      "82 0.2955290973186493\n",
      "83 0.2951814830303192\n",
      "84 0.2948438823223114\n",
      "85 0.2945181131362915\n",
      "86 0.2941964864730835\n",
      "87 0.2938809096813202\n",
      "88 0.2935718595981598\n",
      "89 0.2932712137699127\n",
      "90 0.29297906160354614\n",
      "91 0.2926953136920929\n",
      "92 0.2924198508262634\n",
      "93 0.29214897751808167\n",
      "94 0.29188230633735657\n",
      "95 0.2916213870048523\n",
      "96 0.29136544466018677\n",
      "97 0.29111236333847046\n",
      "98 0.29086437821388245\n",
      "99 0.2906171977519989\n",
      "test error ConvNet 53.80% 538.000000/1000\n"
     ]
    }
   ],
   "source": [
    "mini_batch_size=1000;\n",
    "model = ConvNet1()\n",
    "train_model(model, train_input, train_target,mini_batch_size)\n",
    "nb_test_errors = compute_nb_errors(model, test_input, test_target,mini_batch_size)\n",
    "print('test error ConvNet {:0.2f}% {:f}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                   nb_test_errors, test_input.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
